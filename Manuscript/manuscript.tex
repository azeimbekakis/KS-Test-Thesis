\documentclass[12pt, letterpaper, titlepage]{article}

\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage[margin=1in]{geometry}
\usepackage{hyperref}
\hypersetup{colorlinks = true, linkcolor = blue, citecolor=blue, urlcolor = blue}
\usepackage{natbib}
\usepackage{enumitem}
\usepackage{setspace}

\usepackage[pagewise]{lineno}
\linenumbers*[1]
% %% patches to make lineno work better with amsmath
\newcommand*\patchAmsMathEnvironmentForLineno[1]{%
 \expandafter\let\csname old#1\expandafter\endcsname\csname #1\endcsname
 \expandafter\let\csname oldend#1\expandafter\endcsname\csname end#1\endcsname
 \renewenvironment{#1}%
 {\linenomath\csname old#1\endcsname}%
 {\csname oldend#1\endcsname\endlinenomath}}%
\newcommand*\patchBothAmsMathEnvironmentsForLineno[1]{%
 \patchAmsMathEnvironmentForLineno{#1}%
 \patchAmsMathEnvironmentForLineno{#1*}}%

\AtBeginDocument{%
 \patchBothAmsMathEnvironmentsForLineno{equation}%
 \patchBothAmsMathEnvironmentsForLineno{align}%
 \patchBothAmsMathEnvironmentsForLineno{flalign}%
 \patchBothAmsMathEnvironmentsForLineno{alignat}%
 \patchBothAmsMathEnvironmentsForLineno{gather}%
 \patchBothAmsMathEnvironmentsForLineno{multline}%
}



\title{Survey of Misuses of the Kolmogorov–Smirnov-Test}

\author{Anthony Zeimbekakis and Jun Yan\\
\href{mailto:anthony.zeimbekakis@uconn.edu}{\nolinkurl{anthony.zeimbekakis@uconn.edu}}\\
Department of Statistics, University of Connecticut}
\date{January 23, 2021}

\begin{document}
\maketitle

\doublespace

\begin{abstract}
The Kolmogorov–Smirnov (KS) test is one the most popular goodness-of-fit tests for comparing a sample with a hypothesized parametric distribution. Nevertheless, it has often been misused. The standard one-sample KS test applies to independent, continuous data with a hypothesized distribution that is completely specified. It is not uncommon, however, to see in the literature that it was applied to dependent, discrete, or rounded data, with hypothesized distributions containing estimated parameters. For example, it has been “discovered” multiple times that the test is too conservative when the parameters are estimated [e.g. \citet{Steinskog}]. This paper aims to survey the misuses of the KS test, demonstrate their consequences through simulation, and provide remedies as needed.
\end{abstract}


\hypertarget{sec:intro}{%
\section{Introduction}\label{sec:intro}}

The Kolmogorov-Smirnov (K-S) statistic is one of the most popular goodness-of-fit tests for comparing a sample with a hypothesized parametric distribution. Given a sample of n observations, let $S_{n}(x)$ be the empirical cumulative distribution and $F(x)$ be the population cumulative distribution. The K-S statistic is defined by: \[d = max(\lvert F(x)-S_{n}(x) \rvert)\] If the value of $d$ exceeds the critical value given by the table, the null hypothesis that the observations are from a specified distribution is rejected. 

However, the test is often misused. The standard one-sample K-S test applies to independent, continuous data with a hypothesized distribution that is completely satisfied. Often in literature, the test is applied to dependent, discrete, or rounded data, with hypothesized distributions containing estimated parameters. As shown by \citet{Steinskog} and later in this paper, the test is too conservative when the parameters are estimated. Throughout this paper, the cumulative distribution $F(x)$ is standard normal.

To begin, a simple demonstration is performed to show the impact of sample size and replicate tests. For $n$ in $[10, 100, 1000]$, a random standard normal distributions were generated and K-S tests were performed. With the hypothesized distribution of standard normal, the histograms in Figure 1 show that the sample size has little effect on the distribution of P-values.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.8\linewidth]{hist_normal}
  \caption{Histograms of impact of sample size and number of tests on P-value.}
  \label{fig:hist_normal}
\end{figure}

\hypertarget{sec:fitted}{%
\section{Fitted Parameters}\label{sec:fitted}}

The K-S test shows significant issues in the case of fitted parameters.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.8\linewidth]{hist_parametric}
  \caption{Histograms of P-values with parametric bootstrap.}
  \label{fig:hist_parametric}
\end{figure}

\hypertarget{sec:rounded}{%
\section{Rounded Data}\label{sec:rounded}}

The K-S test shows significant issues in the case of rounding data.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.8\linewidth]{hist_rounded}
  \caption{Histograms of P-values with rounded data.}
  \label{fig:hist_rounded}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.8\linewidth]{hist_dgof}
  \caption{Histograms of P-values with dgof package.}
  \label{fig:hist_dgof}
\end{figure}

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.8\linewidth]{hist_dgofsim}
  \caption{Histograms of P-values when simulating p-value.}
  \label{fig:hist_dgofsim}
\end{figure}

\hypertarget{sec:correlation}{%
\section{Problem under Serial Dependence}\label{sec:correlation}}

The K-S test shows significant issues in the case of serial dependence.

\begin{figure}[!ht]
  \centering
  \includegraphics[width=0.8\linewidth]{hist_correlation}
  \caption{Histograms of P-values with correlated data.}
  \label{fig:hist_correlation}
\end{figure}

\hypertarget{sec:conclusion}{%
\section{Conclusion}\label{sec:conclusion}}

Conclusion here.

Adding these to see the full bibliography: 

\citet{Steinskog}
\citet{Weiss}
\citet{Massey}
\citet{Lilliefors}

\bibliographystyle{chicago}
\bibliography{citations.bib}


\end{document}
